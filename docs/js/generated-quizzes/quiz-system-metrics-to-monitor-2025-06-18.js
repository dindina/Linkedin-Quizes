const quizName = "System Metrics to Monitor Quiz";
const quizData = {
    "questions": [
        {
            "question": "When monitoring an API service, why is tracking the P99 (99th percentile) latency often more insightful than tracking the average latency?",
            "hint": "Consider the experience of the majority of your users, especially those experiencing slower responses.",
            "answerOptions": [
                {
                    "text": "Average latency is harder to calculate in real-time for high-volume services.",
                    "rationale": "Average latency is straightforward to calculate and is commonly used. Its difficulty is not the primary reason to prefer P99.",
                    "isCorrect": false
                },
                {
                    "text": "P99 latency provides a better understanding of the worst-case experience for a significant portion of users.",
                    "rationale": "P99 (99th percentile) latency indicates that 99% of requests completed faster than this value. It effectively captures 'tail latency', revealing the experience of the slower 1% of requests, which can significantly impact overall user satisfaction even if the average is good.",
                    "isCorrect": true
                },
                {
                    "text": "P99 latency always indicates the absolute maximum possible response time a user might experience.",
                    "rationale": "P99 captures the 99th percentile, not the absolute maximum. The maximum (P100) could be even higher but might represent an outlier. P99 focuses on a statistically significant 'worst case' for many users.",
                    "isCorrect": false
                },
                {
                    "text": "Average latency is only useful for internal system health monitoring, not for user experience metrics.",
                    "rationale": "Average latency is useful for a general overview of performance, but it can mask issues where a small percentage of requests are very slow. P99 gives a more complete picture of user experience, encompassing more than just the average.",
                    "isCorrect": false
                }
            ]
        },
        {
            "question": "In the context of the USE (Utilization, Saturation, Errors) method for system monitoring, which metric best indicates 'Saturation' for a server's CPU?",
            "hint": "Saturation is about whether a resource has more work than it can handle, leading to queues.",
            "answerOptions": [
                {
                    "text": "CPU Utilization percentage (e.g., 90% CPU usage).",
                    "rationale": "CPU utilization is a 'Utilization' metric, showing how busy the CPU is. While high utilization can lead to saturation, it doesn't directly measure the presence of a backlog or inability to take more work.",
                    "isCorrect": false
                },
                {
                    "text": "CPU run queue length or context switch rate.",
                    "rationale": "CPU run queue length (or load average on Linux/Unix systems) indicates the number of processes waiting for CPU time, directly measuring saturation. A high context switch rate can also indicate the CPU is struggling to keep up with too many processes.",
                    "isCorrect": true
                },
                {
                    "text": "Number of HTTP 5xx errors generated by the server.",
                    "rationale": "HTTP 5xx errors are an 'Error' metric. While saturation can cause errors, this metric doesn't directly measure the saturation itself.",
                    "isCorrect": false
                },
                {
                    "text": "Total available disk space on the server.",
                    "rationale": "Available disk space is a capacity metric and doesn't directly indicate the saturation of the CPU resource.",
                    "isCorrect": false
                }
            ]
        },
        {
            "question": "A critical metric for monitoring the health of any service is the 'Error Rate'. Beyond HTTP 5xx status codes returned to the client, which of the following is also a crucial indicator of internal application-level errors?",
            "hint": "Think about failures that might occur within the application's logic or its interaction with internal dependencies, which might not always result in an immediate HTTP error for the client.",
            "answerOptions": [
                {
                    "text": "Number of concurrent users accessing the service.",
                    "rationale": "This is a load or traffic metric, not an error metric.",
                    "isCorrect": false
                },
                {
                    "text": "Internal application log errors (e.g., uncaught exceptions, failed database transactions, deserialization errors).",
                    "rationale": "These metrics represent failures within the application's business logic, data processing, or internal component interactions. They are critical error indicators even if they don't always translate to an immediate HTTP 5xx status code for the end-user request.",
                    "isCorrect": true
                },
                {
                    "text": "Network latency between the service and its upstream dependencies.",
                    "rationale": "This is a performance or latency metric, indicating slowness, but not necessarily an error on its own, although high latency can lead to timeouts/errors.",
                    "isCorrect": false
                },
                {
                    "text": "Total outgoing network bandwidth utilized by the service.",
                    "rationale": "This is a throughput or resource utilization metric, indicating data transfer volume, not errors.",
                    "isCorrect": false
                }
            ]
        },
        {
            "question": "Your monitoring dashboard shows consistently high throughput (requests per second) for a critical API service. However, user complaints about slow responses are increasing. Which other metric should you immediately investigate to understand this discrepancy?",
            "hint": "High volume doesn't always mean good performance. Think about how long individual requests are taking, especially for the slower ones.",
            "answerOptions": [
                {
                    "text": "CPU utilization of the server.",
                    "rationale": "While high CPU could be a cause, directly checking latency metrics provides a more direct answer to 'slow responses' before diving into resource utilization.",
                    "isCorrect": false
                },
                {
                    "text": "Network I/O rates of the server.",
                    "rationale": "Similar to CPU, high Network I/O could contribute, but latency metrics pinpoint the user experience issue more directly.",
                    "isCorrect": false
                },
                {
                    "text": "P99 Latency (99th percentile response time).",
                    "rationale": "High throughput combined with increasing user complaints about slowness strongly suggests an issue with tail latency. P99 latency will reveal if a significant portion of requests are experiencing long delays, even if the average is acceptable and overall volume is high.",
                    "isCorrect": true
                },
                {
                    "text": "Available disk space on the server.",
                    "rationale": "Unless the service is actively writing large amounts of data, low disk space is unlikely to be the primary cause of high throughput and slow responses. It's more likely to cause failures or prevent new operations.",
                    "isCorrect": false
                }
            ]
        },
        {
            "question": "What does 'high cardinality' mean in the context of monitoring metrics, and why can it be problematic for monitoring systems?",
            "hint": "Consider the number of unique combinations of labels or dimensions associated with a single metric.",
            "answerOptions": [
                {
                    "text": "It means a metric's value changes very rapidly over time, requiring high-frequency sampling.",
                    "rationale": "This describes metric volatility or update frequency, not cardinality.",
                    "isCorrect": false
                },
                {
                    "text": "It refers to a metric having a very large number of unique label combinations (e.g., thousands of unique user IDs), leading to increased storage, processing, and query costs for the monitoring system.",
                    "rationale": "High cardinality means a metric has many unique dimensions, effectively creating a new time series for each unique combination. This can overwhelm monitoring systems due to massive storage requirements, indexing overhead, and slower query performance.",
                    "isCorrect": true
                },
                {
                    "text": "It indicates that a metric is highly correlated with several other system metrics, making it redundant to collect separately.",
                    "rationale": "This describes metric correlation, which can inform data reduction strategies, but it's not the definition of cardinality.",
                    "isCorrect": false
                },
                {
                    "text": "It means the metric's value can only be a small, fixed set of discrete numbers (e.g., HTTP status codes).",
                    "rationale": "This describes low cardinality for the *values* of a metric, not the cardinality of its labels/dimensions.",
                    "isCorrect": false
                }
            ]
        },
        {
            "question": "When monitoring a relational database, beyond standard CPU and memory utilization, which specific metric is most indicative of query performance bottlenecks?",
            "hint": "Think about what directly measures the efficiency of the database's primary function: processing queries.",
            "answerOptions": [
                {
                    "text": "Number of open file descriptors on the database server.",
                    "rationale": "While important for resource limits, this isn't a direct indicator of query performance bottlenecks itself, though running out of them can cause errors.",
                    "isCorrect": false
                },
                {
                    "text": "Database connection pool size and current active connections.",
                    "rationale": "These metrics relate to connection management and capacity. While too few connections can bottleneck, they don't directly measure the performance of individual queries once connected.",
                    "isCorrect": false
                },
                {
                    "text": "Average query execution time or the count of queries exceeding a 'slow query' threshold.",
                    "rationale": "These metrics directly measure how long queries take to complete. Tracking average or, even better, percentile-based query execution times, or identifying specific slow queries, is crucial for pinpointing performance bottlenecks within the database.",
                    "isCorrect": true
                },
                {
                    "text": "Total network bandwidth used by the database server.",
                    "rationale": "This indicates data transfer volume, which is a throughput metric. It doesn't directly tell you about the internal efficiency or slowness of query processing within the database itself.",
                    "isCorrect": false
                }
            ]
        }
    ]
};